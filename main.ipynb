{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/28 16:03:14 WARN Utils: Your hostname, spark-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "24/09/28 16:03:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/spark/.ivy2/cache\n",
      "The jars for the packages stored in: /home/spark/.ivy2/jars\n",
      "com.google.cloud.spark#spark-bigquery-with-dependencies_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0d35e162-324f-4e3e-9439-8ab517d0bc24;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.google.cloud.spark#spark-bigquery-with-dependencies_2.12;0.23.2 in central\n",
      ":: resolution report :: resolve 804ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.cloud.spark#spark-bigquery-with-dependencies_2.12;0.23.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   0   |   0   |   0   ||   1   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0d35e162-324f-4e3e-9439-8ab517d0bc24\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 1 already retrieved (0kB/27ms)\n",
      "24/09/28 16:03:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Criação da sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark BigQuery Connection\") \\\n",
    "    .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.23.2') \\\n",
    "    .config(\"spark.jars\", \"/usr/local/lib/spark-connectors/bigquery-connector-hadoop2-latest.jar\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true -Dio.netty.noUnsafe=true\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true -Dio.netty.noUnsafe=true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"viewsEnabled\", True)\n",
    "spark.conf.set(\"materializationDataset\", \"SOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "sc._jsc.hadoopConfiguration().set('fs.gs.impl', 'com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem')\n",
    "sc._jsc.hadoopConfiguration().set('fs.gs.auth.service.account.json.keyfile', '/usr/local/lib/gcp/credentials/my-project-1508437523553-e9bafe7e3368.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para salvar DataFrame em formato Parquet\n",
    "def save_to_bigquery(df, dataset, table_name):\n",
    "    # Salva o DataFrame em formato Parquet\n",
    "    df.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"table\", f\"{dataset.upper()}.{table_name}\") \\\n",
    "    .option(\"temporaryGcsBucket\", \"meu-bucket-temporario-spark\") \\\n",
    "    .option(\"credentialsFile\", \"/usr/local/lib/gcp/credentials/my-project-1508437523553-e9bafe7e3368.json\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler dados do BigQuery\n",
    "def read_from_bigquery(dataset, table_name):  \n",
    "    df = spark.read \\\n",
    "        .format('bigquery') \\\n",
    "        .option('table', f\"{dataset.upper()}.{table_name}\") \\\n",
    "        .option(\"credentialsFile\", \"/usr/local/lib/gcp/credentials/my-project-1508437523553-e9bafe7e3368.json\") \\\n",
    "        .load()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_from_bigquery('SOT', 'tbx001_data')\n",
    "df.createOrReplaceTempView(\"tbx001_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/28 16:04:34 INFO DirectBigQueryRelation: |Querying table my-project-1508437523553.SOT.tbx001_data, parameters sent from Spark:|requiredColumns=[uf,ano,mes,semana,ano_nascimento,sexo,cor_raca,tipo_area,escolaridade,teve_febre,teve_dificuldade_respirar,teve_dor_cabeca,teve_fadiga,teve_perda_cheiro,foi_posto_saude,ficou_em_casa,ficou_internado,resultado_covid,tem_plano_saude,faixa_rendimento,situacao_domicilio],|filters=[]\n",
      "24/09/28 16:04:39 INFO ReadSessionCreator: Read session:{\"readSessionName\":\"projects/my-project-1508437523553/locations/us-east1/sessions/CAISDGxtR1UtNjlqMGxEYRoCdngaAnVo\",\"readSessionCreationStartTime\":\"2024-09-28T19:04:34.272Z\",\"readSessionCreationEndTime\":\"2024-09-28T19:04:38.979Z\",\"readSessionPrepDuration\":2423,\"readSessionCreationDuration\":2284,\"readSessionDuration\":4707}\n",
      "24/09/28 16:04:39 INFO ReadSessionCreator: Requested 20000 max partitions, but only received 4 from the BigQuery Storage API for session projects/my-project-1508437523553/locations/us-east1/sessions/CAISDGxtR1UtNjlqMGxEYRoCdngaAnVo. Notice that the number of streams in actual may be lower than the requested number, depending on the amount parallelism that is reasonable for the table and the maximum amount of parallelism allowed by the system.\n",
      "24/09/28 16:04:39 INFO BigQueryRDDFactory: Created read session for table 'my-project-1508437523553.SOT.tbx001_data': projects/my-project-1508437523553/locations/us-east1/sessions/CAISDGxtR1UtNjlqMGxEYRoCdngaAnVo\n",
      "24/09/28 16:04:41 INFO CodeGenerator: Code generated in 1161.3531 ms\n",
      "24/09/28 16:04:42 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/28 16:04:42 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/09/28 16:04:42 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/28 16:04:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/28 16:04:42 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/28 16:04:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/28 16:04:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 29.9 KiB, free 366.3 MiB)\n",
      "24/09/28 16:04:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.4 KiB, free 366.3 MiB)\n",
      "24/09/28 16:04:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.15:46161 (size: 12.4 KiB, free: 366.3 MiB)\n",
      "24/09/28 16:04:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/28 16:04:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/28 16:04:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "24/09/28 16:04:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 9268 bytes) \n",
      "24/09/28 16:04:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "24/09/28 16:04:45 INFO CodeGenerator: Code generated in 271.115167 ms0 + 1) / 1]\n",
      "24/09/28 16:04:46 INFO BaseAllocator: Debug mode disabled.\n",
      "24/09/28 16:04:46 INFO DefaultAllocationManagerOption: allocation manager type not specified, using netty as the default type\n",
      "24/09/28 16:04:46 INFO CheckAllocator: Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class\n",
      "24/09/28 16:04:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2269 bytes result sent to driver\n",
      "24/09/28 16:04:49 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5497 ms on 10.0.2.15 (executor driver) (1/1)\n",
      "24/09/28 16:04:49 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "24/09/28 16:04:49 INFO DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 6,468 s\n",
      "24/09/28 16:04:49 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/28 16:04:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "24/09/28 16:04:49 INFO DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 6,848916 s\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+---+------+--------------+-----+--------+---------+--------------------+----------+-------------------------+---------------+-----------+-----------------+---------------+-------------+---------------+---------------+---------------+----------------+------------------+\n",
      "|   uf| ano|mes|semana|ano_nascimento| sexo|cor_raca|tipo_area|        escolaridade|teve_febre|teve_dificuldade_respirar|teve_dor_cabeca|teve_fadiga|teve_perda_cheiro|foi_posto_saude|ficou_em_casa|ficou_internado|resultado_covid|tem_plano_saude|faixa_rendimento|situacao_domicilio|\n",
      "+-----+----+---+------+--------------+-----+--------+---------+--------------------+----------+-------------------------+---------------+-----------+-----------------+---------------+-------------+---------------+---------------+---------------+----------------+------------------+\n",
      "|Amapá|2020| 05|     1|          9999|Homem|   Parda|  Capital|Fundamental incom...|       Sim|                     Não |           Não |       Não |             Não |           Não |         Não |           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          9999|Homem|   Parda|  Capital|    Médio incompleto|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2010|Homem|   Parda|  Capital|Fundamental incom...|       Sim|                     Não |           Não |       Não |             Não |           Não |         Não |           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2008|Homem|   Parda|  Capital|Fundamental incom...|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2003|Homem|   Parda|  Capital|    Médio incompleto|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          1973|Homem|   Parda|  Capital|      Médio completo|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2012|Homem|   Parda|  Capital|Fundamental incom...|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          9999|Homem|   Parda|  Capital|    Médio incompleto|       Sim|                     Não |           Não |       Não |             Não |           Não |         Não |           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          1996|Homem|   Parda|  Capital|      Médio completo|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2005|Homem|  Branca|  Capital|Fundamental incom...|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          1952|Homem|  Branca|  Capital|Fundamental completa|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2016|Homem|   Parda|  Capital|       Sem instrução|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2019|Homem|  Branca|  Capital|       Sem instrução|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          9999|Homem|   Parda|  Capital|Fundamental incom...|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2000|Homem|   Parda|  Capital|Fundamental completa|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2008|Homem|   Parda|  Capital|Fundamental incom...|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          1976|Homem|   Parda|  Capital|   Superior completo|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          1994|Homem|   Parda|  Capital| Superior incompleto|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          2005|Homem|  Branca|  Capital|    Médio incompleto|      Não |                     Não |           Não |       NULL|             NULL|           NULL|         NULL|           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "|Amapá|2020| 05|     1|          1976|Homem|   Parda|  Capital|Fundamental incom...|       Sim|                     Não |           Não |       Não |             Não |           Não |         Não |           NULL|           NULL|           NULL|            NULL|              NULL|\n",
      "+-----+----+---+------+--------------+-----+--------+---------+--------------------+----------+-------------------------+---------------+-----------+-----------------+---------------+-------------+---------------+---------------+---------------+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/28 16:04:52 INFO CodeGenerator: Code generated in 169.636727 ms\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
